# GitHub Actions Workflow - AI Code Review (Heuristic)
#
# This is a TEMPLATE file. To use it:
# 1. Rename to .github/workflows/ai-code-review.yml
# 2. Adjust settings as needed
#
# This workflow runs fast heuristic code review checks on pull requests.
# For comprehensive analysis with bazel coverage, developers should use:
# /envoy-review --rigorous-coverage (locally)
#
# See CLAUDE.md for comparison of heuristic vs rigorous review.

name: AI Code Review (Heuristic)

on:
  pull_request:
    types: [opened, synchronize, reopened]
    paths:
      - 'source/**'
      - 'test/**'
      - 'api/**'
      - '**.cc'
      - '**.h'
      - 'BUILD'
      - '**.bzl'

jobs:
  code-review:
    name: Heuristic Code Review
    runs-on: ubuntu-latest

    permissions:
      contents: read
      pull-requests: write  # Needed to post comments

    steps:
      - name: Checkout PR code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for git diff
          ref: ${{ github.event.pull_request.head.sha }}

      - name: Fetch base branch
        run: |
          git fetch origin ${{ github.base_ref }}:${{ github.base_ref }}

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          # Add any Python dependencies if needed

      - name: Run Envoy Code Reviewer Helper
        id: review
        continue-on-error: true  # Don't fail workflow on review issues
        run: |
          chmod +x ./scripts/envoy-review-helper.py

          ./scripts/envoy-review-helper.py \
            --repo . \
            --base ${{ github.base_ref }} \
            --format markdown > /tmp/review-report.md

          # Capture exit code
          echo "exit_code=$?" >> $GITHUB_OUTPUT

          # Save report
          cat /tmp/review-report.md

      - name: Read review report
        id: report
        run: |
          # Read the report and escape for JSON
          REPORT=$(cat /tmp/review-report.md)

          # Save to output (handle multiline)
          echo "content<<EOF" >> $GITHUB_OUTPUT
          echo "$REPORT" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      - name: Check for critical issues
        id: check-critical
        run: |
          if grep -q "❌ Critical Issues" /tmp/review-report.md; then
            echo "has_critical=true" >> $GITHUB_OUTPUT
            echo "::warning::Critical issues found in code review"
          else
            echo "has_critical=false" >> $GITHUB_OUTPUT
          fi

      - name: Post review comment
        uses: actions/github-script@v7
        with:
          script: |
            const report = `${{ steps.report.outputs.content }}`;
            const hasCritical = '${{ steps.check-critical.outputs.has_critical }}' === 'true';

            const statusIcon = hasCritical ? '⚠️' : '✅';
            const statusText = hasCritical ? 'Issues Found' : 'Looks Good';

            const comment = `## ${statusIcon} AI Code Review (Heuristic) - ${statusText}

            ${report}

            ---

            ### 📌 Next Steps

            ${hasCritical ?
              '- ⚠️  **Action Required**: Please address the critical issues above before merging\n- Run \`/envoy-review\` locally for comprehensive analysis\n- Run \`/envoy-review --rigorous-coverage\` for 100% accurate coverage verification\n- Update this PR and the review will re-run automatically' :
              '- ✅ No critical issues found by heuristic check!\n- Run \`/envoy-review --rigorous-coverage\` locally for 100% accurate verification\n- Human reviewers should still verify architecture and logic\n- Consider addressing warnings and suggestions if applicable'
            }

            ### 🤖 About This Review

            **Type:** Fast heuristic analysis (~90% accuracy, ~2-5 seconds)

            This automated review checks:
            - ✅ Test coverage (heuristic test file detection)
            - ✅ Release notes for user-facing changes
            - ✅ Code style compliance
            - ✅ Envoy-specific patterns (time(), shared_ptr, thread safety, etc.)
            - ✅ Build system correctness
            - ✅ Documentation completeness

            **For 100% accurate coverage verification:**
            - Locally: Run \`/envoy-review --rigorous-coverage\`
            - This executes actual \`bazel coverage\` in Docker (5-10 min)

            **Resources:**
            - [Development Guide](../CLAUDE.md) - Comparison of review tools
            - [Code Reviewer Agent](../.claude/agents/README.md) - Interactive agent docs
            - [Contributing Guide](../CONTRIBUTING.md) - Envoy policies

            *Generated by [Envoy Code Review Helper Script](../scripts/envoy-review-helper.py)*
            `;

            // Find existing bot comment if any
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });

            const botComment = comments.find(comment =>
              comment.user.type === 'Bot' &&
              comment.body.includes('AI Code Review')
            );

            if (botComment) {
              // Update existing comment
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: comment
              });
              console.log('Updated existing review comment');
            } else {
              // Create new comment
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: comment
              });
              console.log('Created new review comment');
            }

      - name: Add labels based on review
        uses: actions/github-script@v7
        if: steps.check-critical.outputs.has_critical == 'true'
        with:
          script: |
            await github.rest.issues.addLabels({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              labels: ['needs-work', 'ai-review-issues']
            });

      - name: Create review summary
        run: |
          echo "## Code Review Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ "${{ steps.check-critical.outputs.has_critical }}" = "true" ]; then
            echo "⚠️  **Critical issues found** - see PR comments for details" >> $GITHUB_STEP_SUMMARY
          else
            echo "✅ **No critical issues** - ready for human review" >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Full report posted as PR comment" >> $GITHUB_STEP_SUMMARY

      # Optional: Fail the check if critical issues found
      # Uncomment to block merging on critical issues
      # - name: Fail on critical issues
      #   if: steps.check-critical.outputs.has_critical == 'true'
      #   run: |
      #     echo "::error::Critical issues found. Please address before merging."
      #     exit 1

  # Optional: Run format checks
  format-check:
    name: Code Format Check
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Check code format
        run: |
          # This would run Envoy's format checker
          # Adjust based on your Bazel setup
          echo "Format check would run here"
          # bazel run //tools/code_format:check_format -- check

  # Optional: Run specific tests related to changed files
  quick-tests:
    name: Quick Tests
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Run tests for changed files
        run: |
          # This would run tests for modified files
          # Adjust based on your Bazel setup
          echo "Targeted tests would run here"
          # ./scripts/run-affected-tests.sh
